from __future__ import annotations

import json
import re
from typing import Dict, Tuple

_INFOBOX_MARKERS = ("è§’è‰²ä¿¡æ¯", "infobox")
_SECTION_PATTERN = re.compile(r"^(={2,})\s*(.+?)\s*\1\s*$")


def _clean_template(content: str, *, site: str | None) -> str:
    parts = [part.strip() for part in content.split("|")]
    if not parts:
        return ""
    name = parts[0]
    params = [part for part in parts[1:] if part]

    if name in ("æç¤º", "notice", "tip"):
        # Bwiki uses æç¤ºæ¨¡æ¿æ‰¿è½½ç¿»è¯‘/è­¦å‘Šä¿¡æ¯ï¼Œä¿ç•™æ­£æ–‡å‚æ•°
        for param in params:
            if "=" in param:
                continue
            return param
        return ""

    if name in ("lang", "lj", "ruby"):
        for param in reversed(params):
            if param and "=" not in param:
                return param
        return ""

    if site == "biligame":
        # Bwiki é¡µé¢å€¾å‘äºç”¨æ¨¡æ¿åŒ…è£¹å­—æ®µï¼Œå°½é‡ä¿ç•™æœ€åå¯è§æ–‡æœ¬
        for param in reversed(params):
            if param and "=" not in param:
                return param
        return ""

    # é»˜è®¤ç­–ç•¥ï¼šä¿ç•™æœ€åä¸€ä¸ªéç©ºå‚æ•°
    for param in reversed(params):
        if param and "=" not in param:
            return param
    return ""


def clean_wiki_value(text: str, *, site: str | None = None) -> str:
    """æ¸©å’Œæ¸…æ´— Wiki æ–‡æœ¬ï¼Œå°½é‡ä¿ç•™å†…å®¹ã€‚"""
    if not text:
        return ""
    text = re.sub(r"\[\[(?:[^|\]]*\|)?([^\]]+)\]\]", r"\1", text)
    text = re.sub(r"'{2,5}(.*?)'{2,5}", r"\1", text)
    text = re.sub(r"<(br|BR|Br)\s*/?>", "\n", text)

    def replace_template(match: re.Match[str]) -> str:
        return _clean_template(match.group(1), site=site)

    text = re.sub(r"\{\{(.*?)\}\}", replace_template, text)
    text = re.sub(r"<.*?>", "", text)
    return text.strip()


def clean_wikitext_for_llm(text: str, *, site: str | None = None) -> str:
    """è½»é‡æ¸…æ´—ï¼šä¿ç•™ç»“æ„ä¸å†…å®¹ï¼Œåªå»å™ªéŸ³ã€‚"""
    if not text:
        return ""

    text = re.sub(r"\[\[(?:[^|\]]*\|)?([^\]]+)\]\]", r"[\1]", text)
    text = re.sub(r"<ref[^>]*>(.*?)</ref>", r" (\1) ", text, flags=re.DOTALL)
    text = re.sub(r"<ref[^>]*/>", "", text)
    text = re.sub(r"<(br|BR|Br)\s*/?>", "\n", text)
    text = re.sub(
        r"</?(div|span|center|font|big|small|table|tr|td|th)[^>]*>", " ", text
    )

    def replace_template(match: re.Match[str]) -> str:
        content = match.group(1).strip()
        if content.startswith(":"):
            return f"\n> ğŸ”— **å…³è”é¡µé¢**: {content[1:].strip()}\n"
        return _clean_template(content, site=site)

    for _ in range(3):
        text = re.sub(r"\{\{(.*?)\}\}", replace_template, text)

    def heading_replace(match: re.Match[str]) -> str:
        level = len(match.group(1))
        title = match.group(2).strip()
        return f"{'#' * level} {title}"

    text = re.sub(r"^(=+)\s*(.*?)\s*\1$", heading_replace, text, flags=re.MULTILINE)

    lines: list[str] = []
    for line in text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if stripped.startswith("|") and "=" in stripped:
            key, val = stripped[1:].split("=", 1)
            key = key.strip()
            val = val.strip()
            if key and val:
                lines.append(f"- **{key}**: {val}")
            else:
                lines.append(stripped)
        else:
            lines.append(stripped)
    return "\n".join(lines).strip()


def _extract_infobox_block(wikitext: str) -> Tuple[str, int, int]:
    if not wikitext:
        return "", -1, -1
    for match in re.finditer(r"\{\{", wikitext):
        start = match.start()
        preview = wikitext[start : start + 120].lower()
        if not any(marker in preview for marker in _INFOBOX_MARKERS):
            continue
        depth = 0
        i = start
        while i < len(wikitext):
            if wikitext.startswith("{{", i):
                depth += 1
                i += 2
                continue
            if wikitext.startswith("}}", i):
                depth -= 1
                i += 2
                if depth == 0:
                    return wikitext[start:i], start, i
                continue
            i += 1
    return "", -1, -1


def _parse_infobox_fields(infobox_raw: str, *, site: str | None) -> Dict[str, str]:
    data: Dict[str, str] = {}
    current_key = ""
    buffer: list[str] = []
    for raw_line in infobox_raw.splitlines():
        line = raw_line.rstrip()
        if line.startswith("|") and "=" in line:
            if current_key:
                value = "\n".join(buffer).strip()
                cleaned = clean_wiki_value(value, site=site)
                if cleaned:
                    data[current_key] = cleaned
            key, value = line[1:].split("=", 1)
            current_key = key.strip()
            buffer = [value.strip()]
        elif current_key:
            buffer.append(line.strip())
    if current_key:
        value = "\n".join(buffer).strip()
        cleaned = clean_wiki_value(value, site=site)
        if cleaned:
            data[current_key] = cleaned
    return data


def _extract_transclusions(wikitext: str) -> list[str]:
    titles: list[str] = []
    for match in re.finditer(r"\{\{:\s*([^}|]+)", wikitext):
        title = match.group(1).strip()
        if title and title not in titles:
            titles.append(title)
    return titles


def _split_sections(wikitext: str, *, site: str | None) -> list[dict[str, str]]:
    sections: list[dict[str, str]] = []
    current_heading = "intro"
    buffer: list[str] = []

    def flush() -> None:
        if not buffer:
            return
        raw = "\n".join(buffer).strip()
        cleaned = clean_wiki_value(raw, site=site)
        if cleaned:
            sections.append({"heading": current_heading, "content": cleaned})

    for line in wikitext.splitlines():
        match = _SECTION_PATTERN.match(line)
        if match:
            flush()
            current_heading = match.group(2).strip() or "section"
            buffer = []
            continue
        buffer.append(line)
    flush()
    return sections


def parse_wiki_page(
    wikitext: str, *, site: str | None = None
) -> Dict[str, str | Dict[str, str] | list[dict[str, str]] | list[str]]:
    """è§£ææ•´é¡µå†…å®¹ï¼Œè¿”å› infobox + intro + raw_text + raw_wikitext + sections + transclusionsã€‚"""
    if not wikitext:
        return {
            "infobox": {},
            "intro": "",
            "raw_text": "",
            "raw_wikitext": "",
            "sections": [],
            "transclusions": [],
        }

    infobox_raw, start, end = _extract_infobox_block(wikitext)
    remaining_text = wikitext
    infobox_data: Dict[str, str] = {}
    if infobox_raw:
        infobox_data = _parse_infobox_fields(infobox_raw, site=site)
        remaining_text = (wikitext[:start] + wikitext[end:]).strip()

    transclusions = _extract_transclusions(remaining_text)
    sections = _split_sections(remaining_text, site=site)
    intro_text = sections[0]["content"] if sections else ""
    raw_text = "\n\n".join(
        f"{section['heading']}\n{section['content']}" if section["heading"] != "intro" else section["content"]
        for section in sections
    ).strip()

    return {
        "infobox": infobox_data,
        "intro": intro_text,
        "raw_text": raw_text,
        "raw_wikitext": remaining_text,
        "sections": sections,
        "transclusions": transclusions,
    }


def parse_wiki_infobox(wikitext: str, *, site: str | None = None) -> Dict[str, str]:
    """å…¼å®¹æ—§æ¥å£ï¼šä»…è¿”å›ä¿¡æ¯æ¡†å­—æ®µã€‚"""
    payload = parse_wiki_page(wikitext, site=site)
    return payload.get("infobox", {})  # type: ignore[return-value]


def wiki_page_to_markdown(
    title: str, page: Dict[str, str | Dict[str, str] | list[dict[str, str]] | list[str]]
) -> str:
    heading = title.strip() if title else "Wiki Page"
    lines = [f"# {heading}"]
    intro = page.get("intro", "")
    if intro:
        lines.extend(["", "## Intro", str(intro)])
    infobox = page.get("infobox", {})
    lines.extend(["", "## Infobox"])
    if isinstance(infobox, dict) and infobox:
        lines.extend(["| Key | Value |", "| --- | --- |"])
        for key, value in infobox.items():
            safe_value = str(value).replace("\n", "<br>")
            lines.append(f"| {key} | {safe_value} |")
    else:
        lines.append("_No infobox fields found._")
    raw_text = page.get("raw_text", "")
    if raw_text:
        lines.append("")
        lines.append("## Body")
        sections = page.get("sections", [])
        if isinstance(sections, list) and sections:
            for section in sections:
                if not isinstance(section, dict):
                    continue
                section_heading = section.get("heading", "section")
                section_content = section.get("content", "")
                if section_heading and section_heading != "intro":
                    lines.append(f"### {section_heading}")
                if section_content:
                    lines.append(str(section_content))
                    lines.append("")
        else:
            lines.append(str(raw_text))
    transclusions = page.get("transclusions", [])
    if isinstance(transclusions, list) and transclusions:
        lines.append("## Transclusions")
        for title in transclusions:
            lines.append(f"- {title}")
    return "\n".join(lines)


def wiki_page_to_llm_markdown(
    title: str,
    page: Dict[str, str | Dict[str, str] | list[dict[str, str]] | list[str]],
    *,
    site: str | None = None,
) -> str:
    heading = title.strip() if title else "Wiki Page"
    lines = [f"# {heading}"]
    infobox = page.get("infobox", {})
    if isinstance(infobox, dict) and infobox:
        lines.extend(["", "## Infobox"])
        for key, value in infobox.items():
            safe_value = str(value).replace("\n", " ")
            lines.append(f"- **{key}**: {safe_value}")
    raw_wikitext = page.get("raw_wikitext", "")
    if raw_wikitext:
        cleaned = clean_wikitext_for_llm(str(raw_wikitext), site=site)
        if cleaned:
            lines.extend(["", "## Body", cleaned])
    transclusions = page.get("transclusions", [])
    if isinstance(transclusions, list) and transclusions:
        lines.append("")
        lines.append("## Transclusions")
        for title in transclusions:
            lines.append(f"- {title}")
    return "\n".join(lines)


if __name__ == "__main__":
    raw_api_text_moegirl = """
{{Umamusumetop}}
{{èµ›é©¬å¨˜è§’è‰²ä¿¡æ¯2
|ä¸»å°è±¡è‰²=#3376D2
|ä¸­æ–‡å=ä¸œæµ·å¸ç‹
|æ—¥æ–‡å=ãƒˆã‚¦ã‚«ã‚¤ãƒ†ã‚¤ã‚ªãƒ¼
|å›¾ç‰‡=92042198 p0.jpg
|å£°ä¼˜=Machico
|èº«é«˜=150
|ä¸‰å›´=B77 W54 H76
|ç”Ÿæ—¥=4/20
|èŒç‚¹=[[é©¬å¨˜]]ã€[[å…½è€³]]
|ç®€ä»‹=è¿™æ˜¯ç¬¬ä¸€è¡Œã€‚
è¿™æ˜¯ç¬¬äºŒè¡Œã€‚
è¿™æ˜¯ç¬¬ä¸‰è¡Œã€‚
}}
'''ä¸œæµ·å¸ç‹'''æ˜¯[[Cygames]]åˆ¶ä½œçš„...
== ç”Ÿå¹³ ==
å‡ºç”ŸäºåŒ—æµ·é“...
"""

    clean_data = parse_wiki_page(raw_api_text_moegirl, site="moegirl")
    print("â¬‡ï¸ æ¸…æ´—åçš„ç»“æ„åŒ–æ•°æ® â¬‡ï¸")
    print(json.dumps(clean_data, indent=4, ensure_ascii=False))
